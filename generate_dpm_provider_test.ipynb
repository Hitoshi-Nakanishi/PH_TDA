{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/notebooks/DockerShared/Pytorch3/TDA_hofer_2017/tda-toolkit/pershombox/_software_backends/resource_handler.py:91: UserWarning: The following backends are not properly configured\n",
      "dipha\n",
      "hera_wasserstein_dist\n",
      "perseus\n",
      "Using stuff dependent on those backends will cause runtime errors.\n",
      "You can get all errors by calling pershombox.get_backend_cfg_errors().\n",
      "\n",
      "  warnings.warn(error_text, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import os, sys, time\n",
    "import numpy as np\n",
    "cwd = os.getcwd()\n",
    "parent = os.path.join(cwd, os.path.join(os.path.dirname(\"__file__\")))\n",
    "sys.path.append(os.path.join(parent, 'chofer_torchex'))\n",
    "sys.path.append(os.path.join(parent, 'tda-toolkit'))\n",
    "\n",
    "from src.animal.generate_dgm_provider import generate_dgm_provider\n",
    "from src.animal.experiments import experiment\n",
    "from src.sharedCode.data_downloader import download_provider, download_raw_data\n",
    "from src.sharedCode.gui import ask_user_for_provider_or_data_set_download\n",
    "provider_path = os.path.join(os.path.dirname(\"__file__\"), 'data/dgm_provider/npht_animal_32dirs_from_raw.h5')\n",
    "raw_data_path = os.path.join(os.path.dirname(\"__file__\"), 'data/raw_data/animal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "STARTdone 0/2000\n",
      "Jobs done: 1999/2000   Remaining time: 0:00:00\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-3:\n",
      "Process ForkPoolWorker-1:\n",
      "Process ForkPoolWorker-5:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    719\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 720\u001b[0;31m                 \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_items\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopleft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    721\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: pop from an empty deque",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-c6d31d1b7aec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# download_raw_data(\"animal\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgenerate_dgm_provider\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_data_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprovider_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/notebooks/DockerShared/Pytorch3/TDA_hofer_2017/src/animal/generate_dgm_provider.py\u001b[0m in \u001b[0;36mgenerate_dgm_provider\u001b[0;34m(data_path, output_file_path, number_of_directions, n_cores)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0merrors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"START\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimap_unordered\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m\u001b[0;36m1999\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mcontinue\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    722\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_length\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 724\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    725\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m                     \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_items\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopleft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# download_raw_data(\"animal\")\n",
    "generate_dgm_provider(raw_data_path, provider_path, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io\n",
    "import scipy.misc\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "sample_file_path = \"data/raw_data/animal/bird/bird1.tif\"\n",
    "# same \n",
    "img = io.imread(sample_file_path, as_gray=True).astype(np.float32)\n",
    "img1 = scipy.misc.imread(sample_file_path, flatten=True)\n",
    "img2 = imageio.imread(sample_file_path)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import multiprocessing\n",
    "from skimage import io\n",
    "import scipy.ndimage\n",
    "\n",
    "from src.sharedCode.fileSys import Folder\n",
    "from src.sharedCode.gui import SimpleProgressCounter\n",
    "from src.sharedCode.provider import Provider\n",
    "from src.sharedCode.generate_dgm_provider_shapes import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path, output_file_path, number_of_directions = \\\n",
    "raw_data_path, provider_path, 32\n",
    "\n",
    "if not os.path.exists(os.path.dirname(output_file_path)):\n",
    "    print(os.path.dirname(output_file_path), 'does not exist.')\n",
    "src_folder = Folder(data_path)\n",
    "class_folders = src_folder.folders()\n",
    "n = sum([len(cf.files(name_pred=lambda n: n != 'Thumbs.db')) for cf in class_folders])\n",
    "progress = SimpleProgressCounter(n)\n",
    "progress.display()\n",
    "views = {}\n",
    "for i in range(0, number_of_directions):\n",
    "    views['dim_0_dir_{}'.format(i)] = {}\n",
    "    views['dim_1_dir_{}'.format(i)] = {}\n",
    "job_args = []\n",
    "for class_folder in class_folders:\n",
    "    for view in views.values():\n",
    "        view[class_folder.name] = {}\n",
    "    for sample_file in class_folder.files(name_pred=lambda name: name != 'Thumbs.db'):\n",
    "        args = {'file_path': sample_file.path,\n",
    "                'label': class_folder.name,\n",
    "                'sample_id': sample_file.name,\n",
    "                'number_of_directions': number_of_directions}\n",
    "        job_args.append(args)\n",
    "n_cores = int(multiprocessing.cpu_count()*0.5)\n",
    "\n",
    "\n",
    "def job(args):\n",
    "    import warnings\n",
    "    warnings.filterwarnings('error')#TODO change this ... those errors should not occour\n",
    "    sample_file_path = args['file_path']\n",
    "    label = args['label']\n",
    "    sample_id = args['sample_id']\n",
    "    number_of_directions = args['number_of_directions']\n",
    "    return_value = {'label': label, 'sample_id': sample_id, 'dgms': {}}\n",
    "    img = imageio.imread(sample_file_path)\n",
    "    img = reduce_to_largest_connected_component(img)\n",
    "    try:\n",
    "        npht = get_npht(img, number_of_directions)\n",
    "    except Exception as ex:\n",
    "        return_value['error'] = ex\n",
    "    else:\n",
    "        dgms_dim_0 = [x[0] for x in npht]\n",
    "        dgms_dim_1 = [x[1] for x in npht]\n",
    "        dgms_dim_0 = [threhold_dgm(dgm) for dgm in dgms_dim_0]\n",
    "        dgms_dim_1 = [threhold_dgm(dgm) for dgm in dgms_dim_1]\n",
    "        for dir_i, dgm_0, dgm_1 in zip(range(number_of_directions), dgms_dim_0, dgms_dim_1):\n",
    "            if len(dgm_0) == 0:\n",
    "                return_value['error'] = 'Degenerate diagram detected.'\n",
    "                break\n",
    "            return_value['dgms']['dim_0_dir_{}'.format(dir_i)] = dgm_0\n",
    "            return_value['dgms']['dim_1_dir_{}'.format(dir_i)] = dgm_1\n",
    "    return return_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with multiprocessing.Pool(n_cores) as pool:\n",
    "    errors = []\n",
    "    for i, result in enumerate(pool.imap_unordered(job, job_args)):\n",
    "        label = result['label']\n",
    "        sample_id = result['sample_id']\n",
    "        if 'error' in result:\n",
    "            errors.append((sample_id, result['error']))\n",
    "        else:\n",
    "            for view_id, dgm in result['dgms'].items():\n",
    "                views[view_id][label][sample_id] = dgm\n",
    "        progress.trigger_progress()\n",
    "print('Finished calculation ... writing provider (this may also take some time ;) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prv = Provider()\n",
    "for key, view_data in views.items():\n",
    "    prv.add_view(key, view_data)\n",
    "meta = {'number_of_directions': number_of_directions}\n",
    "prv.add_meta_data(meta)\n",
    "prv.dump_as_h5(output_file_path)\n",
    "if len(errors) > 0:\n",
    "    with open('animal_dgm_creation_errors.txt', 'w') as f:\n",
    "        for k, v in errors:\n",
    "            f.write(k)\n",
    "            f.write(str(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check training code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from src.animal.experiments import _parameters, _data_setup\n",
    "from src.animal.experiments import MyModel, _create_trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading provider...\n",
      "Create data loader...\n"
     ]
    }
   ],
   "source": [
    "params = _parameters()\n",
    "data_path = provider_path\n",
    "params['data_path'] = data_path\n",
    "if torch.cuda.is_available(): params['cuda'] = True\n",
    "print('Data setup...')\n",
    "data_train, data_test, subscripted_views = _data_setup(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(data_train)\n",
    "d1 = dataiter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(d1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1055, 0.9428]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1[0]['dim_0_dir_0'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/notebooks/DockerShared/Pytorch3/TDA_hofer_2017/chofer_torchex/chofer_torchex/nn/slayer.py:338: FutureWarning: Renaming in progress. In future use SLayerExponential.\n",
      "  warnings.warn(\"Renaming in progress. In future use SLayerExponential.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "print('Create model...')\n",
    "model = MyModel(subscripted_views)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyModel(\n",
       "  (pht_sl): SLayerPHT(\n",
       "    (sl_0): SLayerExponential (... -> 75 )\n",
       "    (sl_1): SLayerExponential (... -> 75 )\n",
       "    (sl_2): SLayerExponential (... -> 75 )\n",
       "    (sl_3): SLayerExponential (... -> 75 )\n",
       "    (sl_4): SLayerExponential (... -> 75 )\n",
       "    (sl_5): SLayerExponential (... -> 75 )\n",
       "    (sl_6): SLayerExponential (... -> 75 )\n",
       "    (sl_7): SLayerExponential (... -> 75 )\n",
       "    (sl_8): SLayerExponential (... -> 75 )\n",
       "    (sl_9): SLayerExponential (... -> 75 )\n",
       "    (sl_10): SLayerExponential (... -> 75 )\n",
       "    (sl_11): SLayerExponential (... -> 75 )\n",
       "    (sl_12): SLayerExponential (... -> 75 )\n",
       "    (sl_13): SLayerExponential (... -> 75 )\n",
       "    (sl_14): SLayerExponential (... -> 75 )\n",
       "    (sl_15): SLayerExponential (... -> 75 )\n",
       "    (sl_16): SLayerExponential (... -> 75 )\n",
       "    (sl_17): SLayerExponential (... -> 75 )\n",
       "    (sl_18): SLayerExponential (... -> 75 )\n",
       "    (sl_19): SLayerExponential (... -> 75 )\n",
       "    (sl_20): SLayerExponential (... -> 75 )\n",
       "    (sl_21): SLayerExponential (... -> 75 )\n",
       "    (sl_22): SLayerExponential (... -> 75 )\n",
       "    (sl_23): SLayerExponential (... -> 75 )\n",
       "    (sl_24): SLayerExponential (... -> 75 )\n",
       "    (sl_25): SLayerExponential (... -> 75 )\n",
       "    (sl_26): SLayerExponential (... -> 75 )\n",
       "    (sl_27): SLayerExponential (... -> 75 )\n",
       "    (sl_28): SLayerExponential (... -> 75 )\n",
       "    (sl_29): SLayerExponential (... -> 75 )\n",
       "    (sl_30): SLayerExponential (... -> 75 )\n",
       "    (sl_31): SLayerExponential (... -> 75 )\n",
       "  )\n",
       "  (stage_1_0): Sequential(\n",
       "    (conv_1): Conv1d(3, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    (conv_2): Conv1d(32, 8, kernel_size=(1,), stride=(1,), bias=False)\n",
       "  )\n",
       "  (stage_1_1): Sequential(\n",
       "    (conv_1): Conv1d(3, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    (conv_2): Conv1d(32, 8, kernel_size=(1,), stride=(1,), bias=False)\n",
       "  )\n",
       "  (stage_1_2): Sequential(\n",
       "    (conv_1): Conv1d(3, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    (conv_2): Conv1d(32, 8, kernel_size=(1,), stride=(1,), bias=False)\n",
       "  )\n",
       "  (stage_1_3): Sequential(\n",
       "    (conv_1): Conv1d(3, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    (conv_2): Conv1d(32, 8, kernel_size=(1,), stride=(1,), bias=False)\n",
       "  )\n",
       "  (stage_1_4): Sequential(\n",
       "    (conv_1): Conv1d(3, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    (conv_2): Conv1d(32, 8, kernel_size=(1,), stride=(1,), bias=False)\n",
       "  )\n",
       "  (stage_1_5): Sequential(\n",
       "    (conv_1): Conv1d(3, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    (conv_2): Conv1d(32, 8, kernel_size=(1,), stride=(1,), bias=False)\n",
       "  )\n",
       "  (stage_1_6): Sequential(\n",
       "    (conv_1): Conv1d(3, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    (conv_2): Conv1d(32, 8, kernel_size=(1,), stride=(1,), bias=False)\n",
       "  )\n",
       "  (stage_1_7): Sequential(\n",
       "    (conv_1): Conv1d(3, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    (conv_2): Conv1d(32, 8, kernel_size=(1,), stride=(1,), bias=False)\n",
       "  )\n",
       "  (stage_1_8): Sequential(\n",
       "    (conv_1): Conv1d(3, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    (conv_2): Conv1d(32, 8, kernel_size=(1,), stride=(1,), bias=False)\n",
       "  )\n",
       "  (stage_1_9): Sequential(\n",
       "    (conv_1): Conv1d(3, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    (conv_2): Conv1d(32, 8, kernel_size=(1,), stride=(1,), bias=False)\n",
       "  )\n",
       "  (stage_1_10): Sequential(\n",
       "    (conv_1): Conv1d(3, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    (conv_2): Conv1d(32, 8, kernel_size=(1,), stride=(1,), bias=False)\n",
       "  )\n",
       "  (stage_1_11): Sequential(\n",
       "    (conv_1): Conv1d(3, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    (conv_2): Conv1d(32, 8, kernel_size=(1,), stride=(1,), bias=False)\n",
       "  )\n",
       "  (stage_1_12): Sequential(\n",
       "    (conv_1): Conv1d(3, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    (conv_2): Conv1d(32, 8, kernel_size=(1,), stride=(1,), bias=False)\n",
       "  )\n",
       "  (stage_1_13): Sequential(\n",
       "    (conv_1): Conv1d(3, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    (conv_2): Conv1d(32, 8, kernel_size=(1,), stride=(1,), bias=False)\n",
       "  )\n",
       "  (stage_1_14): Sequential(\n",
       "    (conv_1): Conv1d(3, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    (conv_2): Conv1d(32, 8, kernel_size=(1,), stride=(1,), bias=False)\n",
       "  )\n",
       "  (stage_1_15): Sequential(\n",
       "    (conv_1): Conv1d(3, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    (conv_2): Conv1d(32, 8, kernel_size=(1,), stride=(1,), bias=False)\n",
       "  )\n",
       "  (stage_1_16): Sequential(\n",
       "    (conv_1): Conv1d(3, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    (conv_2): Conv1d(32, 8, kernel_size=(1,), stride=(1,), bias=False)\n",
       "  )\n",
       "  (stage_1_17): Sequential(\n",
       "    (conv_1): Conv1d(3, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    (conv_2): Conv1d(32, 8, kernel_size=(1,), stride=(1,), bias=False)\n",
       "  )\n",
       "  (stage_1_18): Sequential(\n",
       "    (conv_1): Conv1d(3, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    (conv_2): Conv1d(32, 8, kernel_size=(1,), stride=(1,), bias=False)\n",
       "  )\n",
       "  (stage_1_19): Sequential(\n",
       "    (conv_1): Conv1d(3, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    (conv_2): Conv1d(32, 8, kernel_size=(1,), stride=(1,), bias=False)\n",
       "  )\n",
       "  (stage_1_20): Sequential(\n",
       "    (conv_1): Conv1d(3, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    (conv_2): Conv1d(32, 8, kernel_size=(1,), stride=(1,), bias=False)\n",
       "  )\n",
       "  (stage_1_21): Sequential(\n",
       "    (conv_1): Conv1d(3, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    (conv_2): Conv1d(32, 8, kernel_size=(1,), stride=(1,), bias=False)\n",
       "  )\n",
       "  (stage_1_22): Sequential(\n",
       "    (conv_1): Conv1d(3, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    (conv_2): Conv1d(32, 8, kernel_size=(1,), stride=(1,), bias=False)\n",
       "  )\n",
       "  (stage_1_23): Sequential(\n",
       "    (conv_1): Conv1d(3, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    (conv_2): Conv1d(32, 8, kernel_size=(1,), stride=(1,), bias=False)\n",
       "  )\n",
       "  (stage_1_24): Sequential(\n",
       "    (conv_1): Conv1d(3, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    (conv_2): Conv1d(32, 8, kernel_size=(1,), stride=(1,), bias=False)\n",
       "  )\n",
       "  (stage_1_25): Sequential(\n",
       "    (conv_1): Conv1d(3, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    (conv_2): Conv1d(32, 8, kernel_size=(1,), stride=(1,), bias=False)\n",
       "  )\n",
       "  (stage_1_26): Sequential(\n",
       "    (conv_1): Conv1d(3, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    (conv_2): Conv1d(32, 8, kernel_size=(1,), stride=(1,), bias=False)\n",
       "  )\n",
       "  (stage_1_27): Sequential(\n",
       "    (conv_1): Conv1d(3, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    (conv_2): Conv1d(32, 8, kernel_size=(1,), stride=(1,), bias=False)\n",
       "  )\n",
       "  (stage_1_28): Sequential(\n",
       "    (conv_1): Conv1d(3, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    (conv_2): Conv1d(32, 8, kernel_size=(1,), stride=(1,), bias=False)\n",
       "  )\n",
       "  (stage_1_29): Sequential(\n",
       "    (conv_1): Conv1d(3, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    (conv_2): Conv1d(32, 8, kernel_size=(1,), stride=(1,), bias=False)\n",
       "  )\n",
       "  (stage_1_30): Sequential(\n",
       "    (conv_1): Conv1d(3, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    (conv_2): Conv1d(32, 8, kernel_size=(1,), stride=(1,), bias=False)\n",
       "  )\n",
       "  (stage_1_31): Sequential(\n",
       "    (conv_1): Conv1d(3, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    (conv_2): Conv1d(32, 8, kernel_size=(1,), stride=(1,), bias=False)\n",
       "  )\n",
       "  (stage_2_0): Sequential(\n",
       "    (linear_1): Linear(in_features=75, out_features=25, bias=True)\n",
       "    (batch_norm): BatchNorm1d(25, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (linear_2): Linear(in_features=25, out_features=25, bias=True)\n",
       "    (relu): ReLU()\n",
       "    (Dropout): Dropout(p=0.4)\n",
       "  )\n",
       "  (stage_2_1): Sequential(\n",
       "    (linear_1): Linear(in_features=75, out_features=25, bias=True)\n",
       "    (batch_norm): BatchNorm1d(25, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (linear_2): Linear(in_features=25, out_features=25, bias=True)\n",
       "    (relu): ReLU()\n",
       "    (Dropout): Dropout(p=0.4)\n",
       "  )\n",
       "  (stage_2_2): Sequential(\n",
       "    (linear_1): Linear(in_features=75, out_features=25, bias=True)\n",
       "    (batch_norm): BatchNorm1d(25, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (linear_2): Linear(in_features=25, out_features=25, bias=True)\n",
       "    (relu): ReLU()\n",
       "    (Dropout): Dropout(p=0.4)\n",
       "  )\n",
       "  (stage_2_3): Sequential(\n",
       "    (linear_1): Linear(in_features=75, out_features=25, bias=True)\n",
       "    (batch_norm): BatchNorm1d(25, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (linear_2): Linear(in_features=25, out_features=25, bias=True)\n",
       "    (relu): ReLU()\n",
       "    (Dropout): Dropout(p=0.4)\n",
       "  )\n",
       "  (stage_2_4): Sequential(\n",
       "    (linear_1): Linear(in_features=75, out_features=25, bias=True)\n",
       "    (batch_norm): BatchNorm1d(25, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (linear_2): Linear(in_features=25, out_features=25, bias=True)\n",
       "    (relu): ReLU()\n",
       "    (Dropout): Dropout(p=0.4)\n",
       "  )\n",
       "  (stage_2_5): Sequential(\n",
       "    (linear_1): Linear(in_features=75, out_features=25, bias=True)\n",
       "    (batch_norm): BatchNorm1d(25, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (linear_2): Linear(in_features=25, out_features=25, bias=True)\n",
       "    (relu): ReLU()\n",
       "    (Dropout): Dropout(p=0.4)\n",
       "  )\n",
       "  (stage_2_6): Sequential(\n",
       "    (linear_1): Linear(in_features=75, out_features=25, bias=True)\n",
       "    (batch_norm): BatchNorm1d(25, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (linear_2): Linear(in_features=25, out_features=25, bias=True)\n",
       "    (relu): ReLU()\n",
       "    (Dropout): Dropout(p=0.4)\n",
       "  )\n",
       "  (stage_2_7): Sequential(\n",
       "    (linear_1): Linear(in_features=75, out_features=25, bias=True)\n",
       "    (batch_norm): BatchNorm1d(25, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (linear_2): Linear(in_features=25, out_features=25, bias=True)\n",
       "    (relu): ReLU()\n",
       "    (Dropout): Dropout(p=0.4)\n",
       "  )\n",
       "  (stage_2_8): Sequential(\n",
       "    (linear_1): Linear(in_features=75, out_features=25, bias=True)\n",
       "    (batch_norm): BatchNorm1d(25, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (linear_2): Linear(in_features=25, out_features=25, bias=True)\n",
       "    (relu): ReLU()\n",
       "    (Dropout): Dropout(p=0.4)\n",
       "  )\n",
       "  (stage_2_9): Sequential(\n",
       "    (linear_1): Linear(in_features=75, out_features=25, bias=True)\n",
       "    (batch_norm): BatchNorm1d(25, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (linear_2): Linear(in_features=25, out_features=25, bias=True)\n",
       "    (relu): ReLU()\n",
       "    (Dropout): Dropout(p=0.4)\n",
       "  )\n",
       "  (stage_2_10): Sequential(\n",
       "    (linear_1): Linear(in_features=75, out_features=25, bias=True)\n",
       "    (batch_norm): BatchNorm1d(25, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (linear_2): Linear(in_features=25, out_features=25, bias=True)\n",
       "    (relu): ReLU()\n",
       "    (Dropout): Dropout(p=0.4)\n",
       "  )\n",
       "  (stage_2_11): Sequential(\n",
       "    (linear_1): Linear(in_features=75, out_features=25, bias=True)\n",
       "    (batch_norm): BatchNorm1d(25, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (linear_2): Linear(in_features=25, out_features=25, bias=True)\n",
       "    (relu): ReLU()\n",
       "    (Dropout): Dropout(p=0.4)\n",
       "  )\n",
       "  (stage_2_12): Sequential(\n",
       "    (linear_1): Linear(in_features=75, out_features=25, bias=True)\n",
       "    (batch_norm): BatchNorm1d(25, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (linear_2): Linear(in_features=25, out_features=25, bias=True)\n",
       "    (relu): ReLU()\n",
       "    (Dropout): Dropout(p=0.4)\n",
       "  )\n",
       "  (stage_2_13): Sequential(\n",
       "    (linear_1): Linear(in_features=75, out_features=25, bias=True)\n",
       "    (batch_norm): BatchNorm1d(25, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (linear_2): Linear(in_features=25, out_features=25, bias=True)\n",
       "    (relu): ReLU()\n",
       "    (Dropout): Dropout(p=0.4)\n",
       "  )\n",
       "  (stage_2_14): Sequential(\n",
       "    (linear_1): Linear(in_features=75, out_features=25, bias=True)\n",
       "    (batch_norm): BatchNorm1d(25, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (linear_2): Linear(in_features=25, out_features=25, bias=True)\n",
       "    (relu): ReLU()\n",
       "    (Dropout): Dropout(p=0.4)\n",
       "  )\n",
       "  (stage_2_15): Sequential(\n",
       "    (linear_1): Linear(in_features=75, out_features=25, bias=True)\n",
       "    (batch_norm): BatchNorm1d(25, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (linear_2): Linear(in_features=25, out_features=25, bias=True)\n",
       "    (relu): ReLU()\n",
       "    (Dropout): Dropout(p=0.4)\n",
       "  )\n",
       "  (stage_2_16): Sequential(\n",
       "    (linear_1): Linear(in_features=75, out_features=25, bias=True)\n",
       "    (batch_norm): BatchNorm1d(25, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (linear_2): Linear(in_features=25, out_features=25, bias=True)\n",
       "    (relu): ReLU()\n",
       "    (Dropout): Dropout(p=0.4)\n",
       "  )\n",
       "  (stage_2_17): Sequential(\n",
       "    (linear_1): Linear(in_features=75, out_features=25, bias=True)\n",
       "    (batch_norm): BatchNorm1d(25, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (linear_2): Linear(in_features=25, out_features=25, bias=True)\n",
       "    (relu): ReLU()\n",
       "    (Dropout): Dropout(p=0.4)\n",
       "  )\n",
       "  (stage_2_18): Sequential(\n",
       "    (linear_1): Linear(in_features=75, out_features=25, bias=True)\n",
       "    (batch_norm): BatchNorm1d(25, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (linear_2): Linear(in_features=25, out_features=25, bias=True)\n",
       "    (relu): ReLU()\n",
       "    (Dropout): Dropout(p=0.4)\n",
       "  )\n",
       "  (stage_2_19): Sequential(\n",
       "    (linear_1): Linear(in_features=75, out_features=25, bias=True)\n",
       "    (batch_norm): BatchNorm1d(25, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (linear_2): Linear(in_features=25, out_features=25, bias=True)\n",
       "    (relu): ReLU()\n",
       "    (Dropout): Dropout(p=0.4)\n",
       "  )\n",
       "  (stage_2_20): Sequential(\n",
       "    (linear_1): Linear(in_features=75, out_features=25, bias=True)\n",
       "    (batch_norm): BatchNorm1d(25, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (linear_2): Linear(in_features=25, out_features=25, bias=True)\n",
       "    (relu): ReLU()\n",
       "    (Dropout): Dropout(p=0.4)\n",
       "  )\n",
       "  (stage_2_21): Sequential(\n",
       "    (linear_1): Linear(in_features=75, out_features=25, bias=True)\n",
       "    (batch_norm): BatchNorm1d(25, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (linear_2): Linear(in_features=25, out_features=25, bias=True)\n",
       "    (relu): ReLU()\n",
       "    (Dropout): Dropout(p=0.4)\n",
       "  )\n",
       "  (stage_2_22): Sequential(\n",
       "    (linear_1): Linear(in_features=75, out_features=25, bias=True)\n",
       "    (batch_norm): BatchNorm1d(25, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (linear_2): Linear(in_features=25, out_features=25, bias=True)\n",
       "    (relu): ReLU()\n",
       "    (Dropout): Dropout(p=0.4)\n",
       "  )\n",
       "  (stage_2_23): Sequential(\n",
       "    (linear_1): Linear(in_features=75, out_features=25, bias=True)\n",
       "    (batch_norm): BatchNorm1d(25, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (linear_2): Linear(in_features=25, out_features=25, bias=True)\n",
       "    (relu): ReLU()\n",
       "    (Dropout): Dropout(p=0.4)\n",
       "  )\n",
       "  (stage_2_24): Sequential(\n",
       "    (linear_1): Linear(in_features=75, out_features=25, bias=True)\n",
       "    (batch_norm): BatchNorm1d(25, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (linear_2): Linear(in_features=25, out_features=25, bias=True)\n",
       "    (relu): ReLU()\n",
       "    (Dropout): Dropout(p=0.4)\n",
       "  )\n",
       "  (stage_2_25): Sequential(\n",
       "    (linear_1): Linear(in_features=75, out_features=25, bias=True)\n",
       "    (batch_norm): BatchNorm1d(25, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (linear_2): Linear(in_features=25, out_features=25, bias=True)\n",
       "    (relu): ReLU()\n",
       "    (Dropout): Dropout(p=0.4)\n",
       "  )\n",
       "  (stage_2_26): Sequential(\n",
       "    (linear_1): Linear(in_features=75, out_features=25, bias=True)\n",
       "    (batch_norm): BatchNorm1d(25, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (linear_2): Linear(in_features=25, out_features=25, bias=True)\n",
       "    (relu): ReLU()\n",
       "    (Dropout): Dropout(p=0.4)\n",
       "  )\n",
       "  (stage_2_27): Sequential(\n",
       "    (linear_1): Linear(in_features=75, out_features=25, bias=True)\n",
       "    (batch_norm): BatchNorm1d(25, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (linear_2): Linear(in_features=25, out_features=25, bias=True)\n",
       "    (relu): ReLU()\n",
       "    (Dropout): Dropout(p=0.4)\n",
       "  )\n",
       "  (stage_2_28): Sequential(\n",
       "    (linear_1): Linear(in_features=75, out_features=25, bias=True)\n",
       "    (batch_norm): BatchNorm1d(25, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (linear_2): Linear(in_features=25, out_features=25, bias=True)\n",
       "    (relu): ReLU()\n",
       "    (Dropout): Dropout(p=0.4)\n",
       "  )\n",
       "  (stage_2_29): Sequential(\n",
       "    (linear_1): Linear(in_features=75, out_features=25, bias=True)\n",
       "    (batch_norm): BatchNorm1d(25, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (linear_2): Linear(in_features=25, out_features=25, bias=True)\n",
       "    (relu): ReLU()\n",
       "    (Dropout): Dropout(p=0.4)\n",
       "  )\n",
       "  (stage_2_30): Sequential(\n",
       "    (linear_1): Linear(in_features=75, out_features=25, bias=True)\n",
       "    (batch_norm): BatchNorm1d(25, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (linear_2): Linear(in_features=25, out_features=25, bias=True)\n",
       "    (relu): ReLU()\n",
       "    (Dropout): Dropout(p=0.4)\n",
       "  )\n",
       "  (stage_2_31): Sequential(\n",
       "    (linear_1): Linear(in_features=75, out_features=25, bias=True)\n",
       "    (batch_norm): BatchNorm1d(25, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (linear_2): Linear(in_features=25, out_features=25, bias=True)\n",
       "    (relu): ReLU()\n",
       "    (Dropout): Dropout(p=0.4)\n",
       "  )\n",
       "  (linear_1): Sequential(\n",
       "    (linear): Linear(in_features=800, out_features=50, bias=True)\n",
       "    (batchnorm): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (drop_out): Dropout(p=0.3)\n",
       "  )\n",
       "  (linear_2): Sequential(\n",
       "    (linear): Linear(in_features=50, out_features=20, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Setup trainer...')\n",
    "trainer = _create_trainer(model, params, data_train, data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Starting...')\n",
    "trainer.run()\n",
    "last_10_accuracies = list(trainer.prediction_monitor.accuracies.values())[-10:]\n",
    "mean = np.mean(last_10_accuracies)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
